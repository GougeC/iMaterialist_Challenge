{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_utils' from '/home/connor/iMaterialist_Challenge/training_utils.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_utils\n",
    "reload(training_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model, Input\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical, Sequence\n",
    "\n",
    "from keras.applications import InceptionV3,inception_v3\n",
    "from keras.applications import VGG16, vgg16\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = json.load(open('data/reformatted_train.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "y = [labels[str(x)]['labelId'] for x in range(1,10000)]\n",
    "y = [[int(x) for x in a] for a in y]\n",
    "largest = 0\n",
    "for l in y:\n",
    "    for num in l:\n",
    "        if num > largest:\n",
    "            largest = num\n",
    "NUM_CLASSES = largest\n",
    "print(largest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"first stupid model\" this is basically just the pretrained convolutional layers with a 1000 unit \n",
    "# fully connected layer before the dense output layer. The output layer is a sigmoid rather than a softmax as the \n",
    "# problem is a multi-label multi-class problem\n",
    "\n",
    "def create_model(base_layers):\n",
    "    for layer in base_layers.layers:\n",
    "        layer.trainable = False\n",
    "    X = base_layers.output\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1000, activation = 'relu', name = 'dense1')(X)\n",
    "    X = Dense(1000, activation = 'relu', name = 'dense2')(X)\n",
    "    predictions = Dense(NUM_CLASSES, activation = 'sigmoid', name = 'outlayer')(X)\n",
    "    model = Model(inputs = base_layers.inputs, outputs = predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3model = create_model(inception_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr = .01, decay = .00001)\n",
    "#rmsprop = keras.optimizers.RMSprop(lr = .01, decay = .00001)\n",
    "#adam = keras.optimizers.Adam(lr = .001, decay = .00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_gen = data_gen.flow(X_train,y_train,seed = 42)\n",
    "training_gen,Xval,yval = training_utils.create_sequence_and_val(labels,1000,10,inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3model.compile(optimizer = sgd, loss =  keras.losses.binary_crossentropy , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "Error sending result: '(array([[[[ 0.23921573,  0.2313726 ,  0.27058828],\n         [ 0.17647064,  0.17647064,  0.19215691],\n         [ 0.09019613,  0.09803927,  0.05882359],\n         ...,\n         [ 0.6784314 ,  0.5686275 ,  0.56078434],\n         [ 0.64705884,  0.5372549 ,  0.5294118 ],\n         [ 0.5764706 ,  0.4666667 ,  0.45882356]],\n\n        [[ 0.22352946,  0.22352946,  0.22352946],\n         [ 0.21568632,  0.21568632,  0.20000005],\n         [ 0.20784318,  0.21568632,  0.17647064],\n         ...,\n         [ 0.67058825,  0.56078434,  0.5529412 ],\n         [ 0.67058825,  0.56078434,  0.5529412 ],\n         [ 0.7411765 ,  0.6313726 ,  0.62352943]],\n\n        [[ 0.14509809,  0.15294123,  0.10588241],\n         [ 0.19215691,  0.20000005,  0.15294123],\n         [ 0.27058828,  0.27843142,  0.2313726 ],\n         ...,\n         [ 0.64705884,  0.5372549 ,  0.5294118 ],\n         [ 0.6313726 ,  0.52156866,  0.5137255 ],\n         [ 0.7254902 ,  0.6156863 ,  0.60784316]],\n\n        ...,\n\n        [[ 0.20784318,  0.20784318,  0.20784318],\n         [ 0.39607847,  0.39607847,  0.39607847],\n         [ 0.33333337,  0.33333337,  0.33333337],\n         ...,\n         [ 0.49803925,  0.49803925,  0.49803925],\n         [ 0.41960788,  0.41960788,  0.41960788],\n         [ 0.5294118 ,  0.5294118 ,  0.5294118 ]],\n\n        [[ 0.36470592,  0.36470592,  0.36470592],\n         [ 0.30196083,  0.30196083,  0.30196083],\n         [ 0.43529415,  0.43529415,  0.43529415],\n         ...,\n         [ 0.49803925,  0.49803925,  0.49803925],\n         [ 0.4901961 ,  0.4901961 ,  0.4901961 ],\n         [ 0.45098042,  0.45098042,  0.45098042]],\n\n        [[ 0.38823533,  0.38823533,  0.38823533],\n         [ 0.3176471 ,  0.3176471 ,  0.3176471 ],\n         [ 0.45882356,  0.45882356,  0.45882356],\n         ...,\n         [ 0.54509807,  0.54509807,  0.54509807],\n         [ 0.5137255 ,  0.5137255 ,  0.5137255 ],\n         [ 0.3176471 ,  0.3176471 ,  0.3176471 ]]],\n\n\n       [[[ 0.6313726 ,  0.4039216 ,  0.26274514],\n         [ 0.60784316,  0.34901965,  0.21568632],\n         [ 0.7411765 ,  0.45098042,  0.30980396],\n         ...,\n         [-0.08235294, -0.372549  , -0.6       ],\n         [-0.01176471, -0.35686272, -0.5686275 ],\n         [-0.03529412, -0.38039213, -0.5921569 ]],\n\n        [[ 0.99215686,  0.7490196 ,  0.52156866],\n         [ 0.85882354,  0.5921569 ,  0.37254906],\n         [ 0.9607843 ,  0.67058825,  0.4431373 ],\n         ...,\n         [-0.06666666, -0.38823527, -0.60784316],\n         [-0.04313725, -0.41176468, -0.64705884],\n         [-0.00392157, -0.372549  , -0.60784316]],\n\n        [[ 0.9372549 ,  0.67058825,  0.37254906],\n         [ 0.8901961 ,  0.6156863 ,  0.3176471 ],\n         [ 0.9137255 ,  0.6       ,  0.3176471 ],\n         ...,\n         [-0.12156862, -0.49019605, -0.7254902 ],\n         [-0.0745098 , -0.49019605, -0.75686276],\n         [-0.02745098, -0.44313723, -0.70980394]],\n\n        ...,\n\n        [[ 0.35686278,  0.082353  , -0.06666666],\n         [ 0.22352946, -0.05098039, -0.19999999],\n         [ 0.19215691, -0.09803921, -0.23921567],\n         ...,\n         [-0.3098039 , -0.56078434, -0.7411765 ],\n         [-0.3490196 , -0.6       , -0.7647059 ],\n         [-0.34117645, -0.5921569 , -0.75686276]],\n\n        [[ 0.41176474,  0.11372554, -0.06666666],\n         [ 0.41960788,  0.09019613, -0.10588235],\n         [ 0.4431373 ,  0.09019613, -0.1372549 ],\n         ...,\n         [-0.4588235 , -0.6784314 , -0.84313726],\n         [-0.40392154, -0.6156863 , -0.7490196 ],\n         [-0.3960784 , -0.60784316, -0.7411765 ]],\n\n        [[ 0.41176474,  0.11372554, -0.06666666],\n         [ 0.45882356,  0.12941182, -0.06666666],\n         [ 0.427451  ,  0.07450986, -0.15294117],\n         ...,\n         [-0.3960784 , -0.6156863 , -0.78039217],\n         [-0.36470586, -0.5764706 , -0.70980394],\n         [-0.3490196 , -0.56078434, -0.69411767]]],\n\n\n       [[[ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         ...,\n         [ 0.6313726 ,  0.6392157 ,  0.6784314 ],\n         [ 0.6313726 ,  0.6392157 ,  0.6784314 ],\n         [ 0.62352943,  0.6313726 ,  0.67058825]],\n\n        [[ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         ...,\n         [ 0.62352943,  0.6313726 ,  0.67058825],\n         [ 0.62352943,  0.6313726 ,  0.67058825],\n         [ 0.62352943,  0.6313726 ,  0.67058825]],\n\n        [[ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         ...,\n         [ 0.62352943,  0.6313726 ,  0.67058825],\n         [ 0.6156863 ,  0.62352943,  0.6627451 ],\n         [ 0.62352943,  0.6313726 ,  0.67058825]],\n\n        ...,\n\n        [[ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         ...,\n         [ 0.7254902 ,  0.7176471 ,  0.75686276],\n         [ 0.7254902 ,  0.7176471 ,  0.75686276],\n         [ 0.7254902 ,  0.7176471 ,  0.75686276]],\n\n        [[ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         ...,\n         [ 0.7176471 ,  0.70980394,  0.7490196 ],\n         [ 0.7176471 ,  0.70980394,  0.7490196 ],\n         [ 0.7176471 ,  0.70980394,  0.7490196 ]],\n\n        [[ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         ...,\n         [ 0.70980394,  0.7019608 ,  0.7411765 ],\n         [ 0.70980394,  0.7019608 ,  0.7411765 ],\n         [ 0.70980394,  0.7019608 ,  0.7411765 ]]],\n\n\n       ...,\n\n\n       [[[ 0.5372549 ,  0.5529412 ,  0.4666667 ],\n         [ 0.8509804 ,  0.92156863,  0.7882353 ],\n         [ 0.84313726,  0.9372549 ,  0.78039217],\n         ...,\n         [ 0.654902  ,  0.6784314 ,  0.5294118 ],\n         [ 0.6784314 ,  0.69411767,  0.58431375],\n         [ 0.6862745 ,  0.69411767,  0.64705884]],\n\n        [[ 0.5137255 ,  0.5294118 ,  0.4431373 ],\n         [ 0.8352941 ,  0.90588236,  0.77254903],\n         [ 0.84313726,  0.9372549 ,  0.7647059 ],\n         ...,\n         [ 0.60784316,  0.6313726 ,  0.4666667 ],\n         [ 0.654902  ,  0.6784314 ,  0.54509807],\n         [ 0.62352943,  0.6313726 ,  0.58431375]],\n\n        [[ 0.45098042,  0.4666667 ,  0.36470592],\n         [ 0.81960785,  0.8901961 ,  0.7411765 ],\n         [ 0.78039217,  0.8745098 ,  0.7019608 ],\n         ...,\n         [ 0.64705884,  0.67058825,  0.5058824 ],\n         [ 0.67058825,  0.69411767,  0.56078434],\n         [ 0.6313726 ,  0.6392157 ,  0.5764706 ]],\n\n        ...,\n\n        [[ 0.52156866,  0.4666667 ,  0.38823533],\n         [ 0.47450984,  0.41960788,  0.2941177 ],\n         [ 0.41960788,  0.36470592,  0.21568632],\n         ...,\n         [ 0.5529412 ,  0.45098042,  0.12156868],\n         [ 0.5921569 ,  0.5058824 ,  0.254902  ],\n         [ 0.7019608 ,  0.64705884,  0.52156866]],\n\n        [[ 0.47450984,  0.45098042,  0.39607847],\n         [ 0.4666667 ,  0.43529415,  0.3411765 ],\n         [ 0.37254906,  0.34901965,  0.2313726 ],\n         ...,\n         [ 0.62352943,  0.52156866,  0.27058828],\n         [ 0.5686275 ,  0.4901961 ,  0.2941177 ],\n         [ 0.6784314 ,  0.64705884,  0.56078434]],\n\n        [[ 0.92941177,  0.94509804,  0.90588236],\n         [ 0.8901961 ,  0.8980392 ,  0.8509804 ],\n         [ 0.9529412 ,  0.9607843 ,  0.9137255 ],\n         ...,\n         [ 1.        ,  0.9843137 ,  0.8901961 ],\n         [ 0.9372549 ,  0.88235295,  0.8039216 ],\n         [ 0.9372549 ,  0.94509804,  0.90588236]]],\n\n\n       [[[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        ...,\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]]],\n\n\n       [[[ 0.5529412 ,  0.16078436,  0.18431377],\n         [ 0.5058824 ,  0.11372554,  0.12156868],\n         [ 0.5137255 ,  0.13725495,  0.12156868],\n         ...,\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n\n        [[ 0.5764706 ,  0.19215691,  0.21568632],\n         [ 0.54509807,  0.18431377,  0.18431377],\n         [ 0.5372549 ,  0.18431377,  0.16078436],\n         ...,\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n\n        [[ 0.5921569 ,  0.2313726 ,  0.24705887],\n         [ 0.5137255 ,  0.1686275 ,  0.16078436],\n         [ 0.5137255 ,  0.1686275 ,  0.14509809],\n         ...,\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n\n        ...,\n\n        [[ 0.84313726,  0.67058825,  0.6862745 ],\n         [ 0.85882354,  0.6862745 ,  0.7019608 ],\n         [ 0.8352941 ,  0.67058825,  0.6627451 ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 0.84313726,  0.67058825,  0.6862745 ],\n         [ 0.84313726,  0.67058825,  0.6862745 ],\n         [ 0.827451  ,  0.6627451 ,  0.654902  ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 0.8352941 ,  0.6627451 ,  0.6784314 ],\n         [ 0.827451  ,  0.654902  ,  0.67058825],\n         [ 0.8117647 ,  0.64705884,  0.6392157 ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]]]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]]))'. Reason: 'OverflowError('cannot serialize a bytes object larger than 4 GiB',)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaybeEncodingError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaybeEncodingError\u001b[0m: Error sending result: '(array([[[[ 0.23921573,  0.2313726 ,  0.27058828],\n         [ 0.17647064,  0.17647064,  0.19215691],\n         [ 0.09019613,  0.09803927,  0.05882359],\n         ...,\n         [ 0.6784314 ,  0.5686275 ,  0.56078434],\n         [ 0.64705884,  0.5372549 ,  0.5294118 ],\n         [ 0.5764706 ,  0.4666667 ,  0.45882356]],\n\n        [[ 0.22352946,  0.22352946,  0.22352946],\n         [ 0.21568632,  0.21568632,  0.20000005],\n         [ 0.20784318,  0.21568632,  0.17647064],\n         ...,\n         [ 0.67058825,  0.56078434,  0.5529412 ],\n         [ 0.67058825,  0.56078434,  0.5529412 ],\n         [ 0.7411765 ,  0.6313726 ,  0.62352943]],\n\n        [[ 0.14509809,  0.15294123,  0.10588241],\n         [ 0.19215691,  0.20000005,  0.15294123],\n         [ 0.27058828,  0.27843142,  0.2313726 ],\n         ...,\n         [ 0.64705884,  0.5372549 ,  0.5294118 ],\n         [ 0.6313726 ,  0.52156866,  0.5137255 ],\n         [ 0.7254902 ,  0.6156863 ,  0.60784316]],\n\n        ...,\n\n        [[ 0.20784318,  0.20784318,  0.20784318],\n         [ 0.39607847,  0.39607847,  0.39607847],\n         [ 0.33333337,  0.33333337,  0.33333337],\n         ...,\n         [ 0.49803925,  0.49803925,  0.49803925],\n         [ 0.41960788,  0.41960788,  0.41960788],\n         [ 0.5294118 ,  0.5294118 ,  0.5294118 ]],\n\n        [[ 0.36470592,  0.36470592,  0.36470592],\n         [ 0.30196083,  0.30196083,  0.30196083],\n         [ 0.43529415,  0.43529415,  0.43529415],\n         ...,\n         [ 0.49803925,  0.49803925,  0.49803925],\n         [ 0.4901961 ,  0.4901961 ,  0.4901961 ],\n         [ 0.45098042,  0.45098042,  0.45098042]],\n\n        [[ 0.38823533,  0.38823533,  0.38823533],\n         [ 0.3176471 ,  0.3176471 ,  0.3176471 ],\n         [ 0.45882356,  0.45882356,  0.45882356],\n         ...,\n         [ 0.54509807,  0.54509807,  0.54509807],\n         [ 0.5137255 ,  0.5137255 ,  0.5137255 ],\n         [ 0.3176471 ,  0.3176471 ,  0.3176471 ]]],\n\n\n       [[[ 0.6313726 ,  0.4039216 ,  0.26274514],\n         [ 0.60784316,  0.34901965,  0.21568632],\n         [ 0.7411765 ,  0.45098042,  0.30980396],\n         ...,\n         [-0.08235294, -0.372549  , -0.6       ],\n         [-0.01176471, -0.35686272, -0.5686275 ],\n         [-0.03529412, -0.38039213, -0.5921569 ]],\n\n        [[ 0.99215686,  0.7490196 ,  0.52156866],\n         [ 0.85882354,  0.5921569 ,  0.37254906],\n         [ 0.9607843 ,  0.67058825,  0.4431373 ],\n         ...,\n         [-0.06666666, -0.38823527, -0.60784316],\n         [-0.04313725, -0.41176468, -0.64705884],\n         [-0.00392157, -0.372549  , -0.60784316]],\n\n        [[ 0.9372549 ,  0.67058825,  0.37254906],\n         [ 0.8901961 ,  0.6156863 ,  0.3176471 ],\n         [ 0.9137255 ,  0.6       ,  0.3176471 ],\n         ...,\n         [-0.12156862, -0.49019605, -0.7254902 ],\n         [-0.0745098 , -0.49019605, -0.75686276],\n         [-0.02745098, -0.44313723, -0.70980394]],\n\n        ...,\n\n        [[ 0.35686278,  0.082353  , -0.06666666],\n         [ 0.22352946, -0.05098039, -0.19999999],\n         [ 0.19215691, -0.09803921, -0.23921567],\n         ...,\n         [-0.3098039 , -0.56078434, -0.7411765 ],\n         [-0.3490196 , -0.6       , -0.7647059 ],\n         [-0.34117645, -0.5921569 , -0.75686276]],\n\n        [[ 0.41176474,  0.11372554, -0.06666666],\n         [ 0.41960788,  0.09019613, -0.10588235],\n         [ 0.4431373 ,  0.09019613, -0.1372549 ],\n         ...,\n         [-0.4588235 , -0.6784314 , -0.84313726],\n         [-0.40392154, -0.6156863 , -0.7490196 ],\n         [-0.3960784 , -0.60784316, -0.7411765 ]],\n\n        [[ 0.41176474,  0.11372554, -0.06666666],\n         [ 0.45882356,  0.12941182, -0.06666666],\n         [ 0.427451  ,  0.07450986, -0.15294117],\n         ...,\n         [-0.3960784 , -0.6156863 , -0.78039217],\n         [-0.36470586, -0.5764706 , -0.70980394],\n         [-0.3490196 , -0.56078434, -0.69411767]]],\n\n\n       [[[ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         ...,\n         [ 0.6313726 ,  0.6392157 ,  0.6784314 ],\n         [ 0.6313726 ,  0.6392157 ,  0.6784314 ],\n         [ 0.62352943,  0.6313726 ,  0.67058825]],\n\n        [[ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         ...,\n         [ 0.62352943,  0.6313726 ,  0.67058825],\n         [ 0.62352943,  0.6313726 ,  0.67058825],\n         [ 0.62352943,  0.6313726 ,  0.67058825]],\n\n        [[ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         ...,\n         [ 0.62352943,  0.6313726 ,  0.67058825],\n         [ 0.6156863 ,  0.62352943,  0.6627451 ],\n         [ 0.62352943,  0.6313726 ,  0.67058825]],\n\n        ...,\n\n        [[ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         ...,\n         [ 0.7254902 ,  0.7176471 ,  0.75686276],\n         [ 0.7254902 ,  0.7176471 ,  0.75686276],\n         [ 0.7254902 ,  0.7176471 ,  0.75686276]],\n\n        [[ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         ...,\n         [ 0.7176471 ,  0.70980394,  0.7490196 ],\n         [ 0.7176471 ,  0.70980394,  0.7490196 ],\n         [ 0.7176471 ,  0.70980394,  0.7490196 ]],\n\n        [[ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         ...,\n         [ 0.70980394,  0.7019608 ,  0.7411765 ],\n         [ 0.70980394,  0.7019608 ,  0.7411765 ],\n         [ 0.70980394,  0.7019608 ,  0.7411765 ]]],\n\n\n       ...,\n\n\n       [[[ 0.5372549 ,  0.5529412 ,  0.4666667 ],\n         [ 0.8509804 ,  0.92156863,  0.7882353 ],\n         [ 0.84313726,  0.9372549 ,  0.78039217],\n         ...,\n         [ 0.654902  ,  0.6784314 ,  0.5294118 ],\n         [ 0.6784314 ,  0.69411767,  0.58431375],\n         [ 0.6862745 ,  0.69411767,  0.64705884]],\n\n        [[ 0.5137255 ,  0.5294118 ,  0.4431373 ],\n         [ 0.8352941 ,  0.90588236,  0.77254903],\n         [ 0.84313726,  0.9372549 ,  0.7647059 ],\n         ...,\n         [ 0.60784316,  0.6313726 ,  0.4666667 ],\n         [ 0.654902  ,  0.6784314 ,  0.54509807],\n         [ 0.62352943,  0.6313726 ,  0.58431375]],\n\n        [[ 0.45098042,  0.4666667 ,  0.36470592],\n         [ 0.81960785,  0.8901961 ,  0.7411765 ],\n         [ 0.78039217,  0.8745098 ,  0.7019608 ],\n         ...,\n         [ 0.64705884,  0.67058825,  0.5058824 ],\n         [ 0.67058825,  0.69411767,  0.56078434],\n         [ 0.6313726 ,  0.6392157 ,  0.5764706 ]],\n\n        ...,\n\n        [[ 0.52156866,  0.4666667 ,  0.38823533],\n         [ 0.47450984,  0.41960788,  0.2941177 ],\n         [ 0.41960788,  0.36470592,  0.21568632],\n         ...,\n         [ 0.5529412 ,  0.45098042,  0.12156868],\n         [ 0.5921569 ,  0.5058824 ,  0.254902  ],\n         [ 0.7019608 ,  0.64705884,  0.52156866]],\n\n        [[ 0.47450984,  0.45098042,  0.39607847],\n         [ 0.4666667 ,  0.43529415,  0.3411765 ],\n         [ 0.37254906,  0.34901965,  0.2313726 ],\n         ...,\n         [ 0.62352943,  0.52156866,  0.27058828],\n         [ 0.5686275 ,  0.4901961 ,  0.2941177 ],\n         [ 0.6784314 ,  0.64705884,  0.56078434]],\n\n        [[ 0.92941177,  0.94509804,  0.90588236],\n         [ 0.8901961 ,  0.8980392 ,  0.8509804 ],\n         [ 0.9529412 ,  0.9607843 ,  0.9137255 ],\n         ...,\n         [ 1.        ,  0.9843137 ,  0.8901961 ],\n         [ 0.9372549 ,  0.88235295,  0.8039216 ],\n         [ 0.9372549 ,  0.94509804,  0.90588236]]],\n\n\n       [[[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        ...,\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]]],\n\n\n       [[[ 0.5529412 ,  0.16078436,  0.18431377],\n         [ 0.5058824 ,  0.11372554,  0.12156868],\n         [ 0.5137255 ,  0.13725495,  0.12156868],\n         ...,\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n\n        [[ 0.5764706 ,  0.19215691,  0.21568632],\n         [ 0.54509807,  0.18431377,  0.18431377],\n         [ 0.5372549 ,  0.18431377,  0.16078436],\n         ...,\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n\n        [[ 0.5921569 ,  0.2313726 ,  0.24705887],\n         [ 0.5137255 ,  0.1686275 ,  0.16078436],\n         [ 0.5137255 ,  0.1686275 ,  0.14509809],\n         ...,\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n\n        ...,\n\n        [[ 0.84313726,  0.67058825,  0.6862745 ],\n         [ 0.85882354,  0.6862745 ,  0.7019608 ],\n         [ 0.8352941 ,  0.67058825,  0.6627451 ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 0.84313726,  0.67058825,  0.6862745 ],\n         [ 0.84313726,  0.67058825,  0.6862745 ],\n         [ 0.827451  ,  0.6627451 ,  0.654902  ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 0.8352941 ,  0.6627451 ,  0.6784314 ],\n         [ 0.827451  ,  0.654902  ,  0.67058825],\n         [ 0.8117647 ,  0.64705884,  0.6392157 ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]]]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]]))'. Reason: 'OverflowError('cannot serialize a bytes object larger than 4 GiB',)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f1a5664f1e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                      \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                      verbose = 1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Error sending result: '(array([[[[ 0.23921573,  0.2313726 ,  0.27058828],\n         [ 0.17647064,  0.17647064,  0.19215691],\n         [ 0.09019613,  0.09803927,  0.05882359],\n         ...,\n         [ 0.6784314 ,  0.5686275 ,  0.56078434],\n         [ 0.64705884,  0.5372549 ,  0.5294118 ],\n         [ 0.5764706 ,  0.4666667 ,  0.45882356]],\n\n        [[ 0.22352946,  0.22352946,  0.22352946],\n         [ 0.21568632,  0.21568632,  0.20000005],\n         [ 0.20784318,  0.21568632,  0.17647064],\n         ...,\n         [ 0.67058825,  0.56078434,  0.5529412 ],\n         [ 0.67058825,  0.56078434,  0.5529412 ],\n         [ 0.7411765 ,  0.6313726 ,  0.62352943]],\n\n        [[ 0.14509809,  0.15294123,  0.10588241],\n         [ 0.19215691,  0.20000005,  0.15294123],\n         [ 0.27058828,  0.27843142,  0.2313726 ],\n         ...,\n         [ 0.64705884,  0.5372549 ,  0.5294118 ],\n         [ 0.6313726 ,  0.52156866,  0.5137255 ],\n         [ 0.7254902 ,  0.6156863 ,  0.60784316]],\n\n        ...,\n\n        [[ 0.20784318,  0.20784318,  0.20784318],\n         [ 0.39607847,  0.39607847,  0.39607847],\n         [ 0.33333337,  0.33333337,  0.33333337],\n         ...,\n         [ 0.49803925,  0.49803925,  0.49803925],\n         [ 0.41960788,  0.41960788,  0.41960788],\n         [ 0.5294118 ,  0.5294118 ,  0.5294118 ]],\n\n        [[ 0.36470592,  0.36470592,  0.36470592],\n         [ 0.30196083,  0.30196083,  0.30196083],\n         [ 0.43529415,  0.43529415,  0.43529415],\n         ...,\n         [ 0.49803925,  0.49803925,  0.49803925],\n         [ 0.4901961 ,  0.4901961 ,  0.4901961 ],\n         [ 0.45098042,  0.45098042,  0.45098042]],\n\n        [[ 0.38823533,  0.38823533,  0.38823533],\n         [ 0.3176471 ,  0.3176471 ,  0.3176471 ],\n         [ 0.45882356,  0.45882356,  0.45882356],\n         ...,\n         [ 0.54509807,  0.54509807,  0.54509807],\n         [ 0.5137255 ,  0.5137255 ,  0.5137255 ],\n         [ 0.3176471 ,  0.3176471 ,  0.3176471 ]]],\n\n\n       [[[ 0.6313726 ,  0.4039216 ,  0.26274514],\n         [ 0.60784316,  0.34901965,  0.21568632],\n         [ 0.7411765 ,  0.45098042,  0.30980396],\n         ...,\n         [-0.08235294, -0.372549  , -0.6       ],\n         [-0.01176471, -0.35686272, -0.5686275 ],\n         [-0.03529412, -0.38039213, -0.5921569 ]],\n\n        [[ 0.99215686,  0.7490196 ,  0.52156866],\n         [ 0.85882354,  0.5921569 ,  0.37254906],\n         [ 0.9607843 ,  0.67058825,  0.4431373 ],\n         ...,\n         [-0.06666666, -0.38823527, -0.60784316],\n         [-0.04313725, -0.41176468, -0.64705884],\n         [-0.00392157, -0.372549  , -0.60784316]],\n\n        [[ 0.9372549 ,  0.67058825,  0.37254906],\n         [ 0.8901961 ,  0.6156863 ,  0.3176471 ],\n         [ 0.9137255 ,  0.6       ,  0.3176471 ],\n         ...,\n         [-0.12156862, -0.49019605, -0.7254902 ],\n         [-0.0745098 , -0.49019605, -0.75686276],\n         [-0.02745098, -0.44313723, -0.70980394]],\n\n        ...,\n\n        [[ 0.35686278,  0.082353  , -0.06666666],\n         [ 0.22352946, -0.05098039, -0.19999999],\n         [ 0.19215691, -0.09803921, -0.23921567],\n         ...,\n         [-0.3098039 , -0.56078434, -0.7411765 ],\n         [-0.3490196 , -0.6       , -0.7647059 ],\n         [-0.34117645, -0.5921569 , -0.75686276]],\n\n        [[ 0.41176474,  0.11372554, -0.06666666],\n         [ 0.41960788,  0.09019613, -0.10588235],\n         [ 0.4431373 ,  0.09019613, -0.1372549 ],\n         ...,\n         [-0.4588235 , -0.6784314 , -0.84313726],\n         [-0.40392154, -0.6156863 , -0.7490196 ],\n         [-0.3960784 , -0.60784316, -0.7411765 ]],\n\n        [[ 0.41176474,  0.11372554, -0.06666666],\n         [ 0.45882356,  0.12941182, -0.06666666],\n         [ 0.427451  ,  0.07450986, -0.15294117],\n         ...,\n         [-0.3960784 , -0.6156863 , -0.78039217],\n         [-0.36470586, -0.5764706 , -0.70980394],\n         [-0.3490196 , -0.56078434, -0.69411767]]],\n\n\n       [[[ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         ...,\n         [ 0.6313726 ,  0.6392157 ,  0.6784314 ],\n         [ 0.6313726 ,  0.6392157 ,  0.6784314 ],\n         [ 0.62352943,  0.6313726 ,  0.67058825]],\n\n        [[ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         ...,\n         [ 0.62352943,  0.6313726 ,  0.67058825],\n         [ 0.62352943,  0.6313726 ,  0.67058825],\n         [ 0.62352943,  0.6313726 ,  0.67058825]],\n\n        [[ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         [ 0.78039217,  0.77254903,  0.8117647 ],\n         ...,\n         [ 0.62352943,  0.6313726 ,  0.67058825],\n         [ 0.6156863 ,  0.62352943,  0.6627451 ],\n         [ 0.62352943,  0.6313726 ,  0.67058825]],\n\n        ...,\n\n        [[ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         ...,\n         [ 0.7254902 ,  0.7176471 ,  0.75686276],\n         [ 0.7254902 ,  0.7176471 ,  0.75686276],\n         [ 0.7254902 ,  0.7176471 ,  0.75686276]],\n\n        [[ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         ...,\n         [ 0.7176471 ,  0.70980394,  0.7490196 ],\n         [ 0.7176471 ,  0.70980394,  0.7490196 ],\n         [ 0.7176471 ,  0.70980394,  0.7490196 ]],\n\n        [[ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         [ 0.90588236,  0.90588236,  0.8901961 ],\n         ...,\n         [ 0.70980394,  0.7019608 ,  0.7411765 ],\n         [ 0.70980394,  0.7019608 ,  0.7411765 ],\n         [ 0.70980394,  0.7019608 ,  0.7411765 ]]],\n\n\n       ...,\n\n\n       [[[ 0.5372549 ,  0.5529412 ,  0.4666667 ],\n         [ 0.8509804 ,  0.92156863,  0.7882353 ],\n         [ 0.84313726,  0.9372549 ,  0.78039217],\n         ...,\n         [ 0.654902  ,  0.6784314 ,  0.5294118 ],\n         [ 0.6784314 ,  0.69411767,  0.58431375],\n         [ 0.6862745 ,  0.69411767,  0.64705884]],\n\n        [[ 0.5137255 ,  0.5294118 ,  0.4431373 ],\n         [ 0.8352941 ,  0.90588236,  0.77254903],\n         [ 0.84313726,  0.9372549 ,  0.7647059 ],\n         ...,\n         [ 0.60784316,  0.6313726 ,  0.4666667 ],\n         [ 0.654902  ,  0.6784314 ,  0.54509807],\n         [ 0.62352943,  0.6313726 ,  0.58431375]],\n\n        [[ 0.45098042,  0.4666667 ,  0.36470592],\n         [ 0.81960785,  0.8901961 ,  0.7411765 ],\n         [ 0.78039217,  0.8745098 ,  0.7019608 ],\n         ...,\n         [ 0.64705884,  0.67058825,  0.5058824 ],\n         [ 0.67058825,  0.69411767,  0.56078434],\n         [ 0.6313726 ,  0.6392157 ,  0.5764706 ]],\n\n        ...,\n\n        [[ 0.52156866,  0.4666667 ,  0.38823533],\n         [ 0.47450984,  0.41960788,  0.2941177 ],\n         [ 0.41960788,  0.36470592,  0.21568632],\n         ...,\n         [ 0.5529412 ,  0.45098042,  0.12156868],\n         [ 0.5921569 ,  0.5058824 ,  0.254902  ],\n         [ 0.7019608 ,  0.64705884,  0.52156866]],\n\n        [[ 0.47450984,  0.45098042,  0.39607847],\n         [ 0.4666667 ,  0.43529415,  0.3411765 ],\n         [ 0.37254906,  0.34901965,  0.2313726 ],\n         ...,\n         [ 0.62352943,  0.52156866,  0.27058828],\n         [ 0.5686275 ,  0.4901961 ,  0.2941177 ],\n         [ 0.6784314 ,  0.64705884,  0.56078434]],\n\n        [[ 0.92941177,  0.94509804,  0.90588236],\n         [ 0.8901961 ,  0.8980392 ,  0.8509804 ],\n         [ 0.9529412 ,  0.9607843 ,  0.9137255 ],\n         ...,\n         [ 1.        ,  0.9843137 ,  0.8901961 ],\n         [ 0.9372549 ,  0.88235295,  0.8039216 ],\n         [ 0.9372549 ,  0.94509804,  0.90588236]]],\n\n\n       [[[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        ...,\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]]],\n\n\n       [[[ 0.5529412 ,  0.16078436,  0.18431377],\n         [ 0.5058824 ,  0.11372554,  0.12156868],\n         [ 0.5137255 ,  0.13725495,  0.12156868],\n         ...,\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n\n        [[ 0.5764706 ,  0.19215691,  0.21568632],\n         [ 0.54509807,  0.18431377,  0.18431377],\n         [ 0.5372549 ,  0.18431377,  0.16078436],\n         ...,\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n\n        [[ 0.5921569 ,  0.2313726 ,  0.24705887],\n         [ 0.5137255 ,  0.1686275 ,  0.16078436],\n         [ 0.5137255 ,  0.1686275 ,  0.14509809],\n         ...,\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n\n        ...,\n\n        [[ 0.84313726,  0.67058825,  0.6862745 ],\n         [ 0.85882354,  0.6862745 ,  0.7019608 ],\n         [ 0.8352941 ,  0.67058825,  0.6627451 ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 0.84313726,  0.67058825,  0.6862745 ],\n         [ 0.84313726,  0.67058825,  0.6862745 ],\n         [ 0.827451  ,  0.6627451 ,  0.654902  ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]],\n\n        [[ 0.8352941 ,  0.6627451 ,  0.6784314 ],\n         [ 0.827451  ,  0.654902  ,  0.67058825],\n         [ 0.8117647 ,  0.64705884,  0.6392157 ],\n         ...,\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ]]]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]]))'. Reason: 'OverflowError('cannot serialize a bytes object larger than 4 GiB',)'"
     ]
    }
   ],
   "source": [
    "iv3model.fit_generator(training_gen,\n",
    "                     epochs = 10,\n",
    "                     steps_per_epoch= 10, \n",
    "                     validation_data = (Xval,yval),\n",
    "                     workers = 4,\n",
    "                     use_multiprocessing = True,\n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "vggmodel = create_model(vgg_base)\n",
    "sgd = keras.optimizers.SGD(lr = .01, decay = .00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_gen,Xval,yval = training_utils.create_sequence_and_val(labels,1000,10,vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggmodel.compile(optimizer = sgd, loss =  keras.losses.binary_crossentropy , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[471,3,224,224]\n\t [[Node: block1_conv1_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_2_0/_427, block1_conv1_1/kernel/read)]]\n\nCaused by op 'block1_conv1_1/convolution', defined at:\n  File \"/home/connor/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/connor/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-6eb4d5e88523>\", line 1, in <module>\n    vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/keras/applications/vgg16.py\", line 116, in VGG16\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3332, in conv2d\n    data_format=tf_data_format)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 639, in convolution\n    op=op)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 308, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 631, in op\n    name=name)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 129, in _non_atrous_convolution\n    name=name)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 396, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[471,3,224,224]\n\t [[Node: block1_conv1_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_2_0/_427, block1_conv1_1/kernel/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[471,3,224,224]\n\t [[Node: block1_conv1_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_2_0/_427, block1_conv1_1/kernel/read)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4b9eb848efc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                      \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                      verbose = 1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2242\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2243\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[471,3,224,224]\n\t [[Node: block1_conv1_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_2_0/_427, block1_conv1_1/kernel/read)]]\n\nCaused by op 'block1_conv1_1/convolution', defined at:\n  File \"/home/connor/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/connor/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-6eb4d5e88523>\", line 1, in <module>\n    vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/keras/applications/vgg16.py\", line 116, in VGG16\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3332, in conv2d\n    data_format=tf_data_format)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 639, in convolution\n    op=op)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 308, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 631, in op\n    name=name)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 129, in _non_atrous_convolution\n    name=name)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 396, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/connor/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[471,3,224,224]\n\t [[Node: block1_conv1_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_2_0/_427, block1_conv1_1/kernel/read)]]\n"
     ]
    }
   ],
   "source": [
    "vggmodel.fit_generator(training_gen,\n",
    "                     epochs = 10,\n",
    "                     steps_per_epoch= 10, \n",
    "                     validation_data = (Xval,yval),\n",
    "                     workers =4,\n",
    "                     use_multiprocessing = True,\n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model1.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 228)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds[:,0]).flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connor/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/connor/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def find_best_f1(true_col,pred_col):\n",
    "    f1s = []\n",
    "    for t in thresholds:\n",
    "        col_hat = pred_col > t\n",
    "        f1 = f1_score(true_col.flatten(),col_hat.flatten())\n",
    "        f1s.append(f1)\n",
    "    if np.all(f1s == 0.0):\n",
    "        return .1, None\n",
    "    else:\n",
    "        best = np.argmax(f1s)\n",
    "        return thresholds[best], f1s[best]\n",
    "\n",
    "optimal_ts = np.zeros((preds.shape))\n",
    "\n",
    "for c in range(0,preds.shape[1]):\n",
    "    \n",
    "    optimal_ts[:,c] = find_best_f1(yval[:,c],preds[:,c])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.06, 0.  , 0.04, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.02, 0.  , 0.04, 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.06,\n",
       "       0.  , 0.  , 0.1 , 0.  , 0.02, 0.03, 0.  , 0.  , 0.  , 0.02, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.01, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.03,\n",
       "       0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.1 , 0.  , 0.  , 0.34,\n",
       "       0.  , 0.  , 0.  , 0.06, 0.  , 0.1 , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.  , 0.02, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.03, 0.  , 0.05, 0.  , 0.03,\n",
       "       0.04, 0.01, 0.01, 0.01, 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.06,\n",
       "       0.  , 0.  , 0.04, 0.  , 0.  , 0.02, 0.06, 0.  , 0.01, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.1 , 0.  , 0.01, 0.  , 0.01, 0.  , 0.  , 0.01, 0.01,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.04, 0.04, 0.  , 0.04, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.02, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  ,\n",
       "       0.03, 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.01, 0.03,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.03, 0.04, 0.11, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.06, 0.01, 0.02, 0.  , 0.01, 0.08, 0.  , 0.  , 0.02, 0.  , 0.  ,\n",
       "       0.  , 0.05, 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05277942923425042\n"
     ]
    }
   ],
   "source": [
    "y_hat = preds > optimal_ts    \n",
    "f1 = f1_score(yval,y_hat,average = 'micro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03076923076923077"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yval[:,10],preds[:,10]> .06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0,1,100,endpoint=False)\n",
    "f1s = []\n",
    "for t in thresholds:\n",
    "    y_hat = preds > t\n",
    "    f1 = f1_score(yval,y_hat,average = 'micro')\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotf1s(threshholds,f1s):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(thresholds,f1s)\n",
    "    best = np.argmax(f1s)\n",
    "    ax.set_title(\"F1 score \\n best thresh: {}, score:{}\".format(thresholds[best],f1s[best]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb02c257be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotf1s(thresholds,f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
